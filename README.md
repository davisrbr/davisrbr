## I'm Davis Brown

I do research in the Math of Machine Learning group at PNNL. I'm particularly interested in interpretability, adversarial examples, and semi-supervised learning. 

I'm also a huge Robert Caro fan, into EA, and have been recently diving deep into what philosophy has to say about concepts, inspired by [this Brandom talk](http://ceur-ws.org/Vol-444/paper13.pdf)!

If any of this is interesting, drop me a line at {my first name}brownr@gmail.com or [twitter](https://twitter.com/davisbrownr). Or you can find me on [Google Scholar](https://scholar.google.com/citations?hl=en&user=zQEbpYYAAAAJ&view_op=list_works&sortby=pubdate) or [curius](https://curius.app/davis-brown).

### Papers
- On the Symmetries of Deep Learning Models and their Internal Representations. [Arxiv link](https://arxiv.org/abs/2205.14258). Appearing at Neurips, 2022.

- Convolutional networks inherit frequency sensitivity from image statistics. [Arxiv link](https://arxiv.org/abs/2210.01257).
 
- An adversarial attack on concept-based interpretability methods. [Arxiv link](https://arxiv.org/abs/2110.07120). In AdvML Frontiers at ICML, 2022.

- The SVD of Convolutional Weights: A CNN Interpretability Framework. [Arxiv link](https://arxiv.org/abs/2208.06894), accompanying [interpretability library](https://github.com/pnnl/DeepDataProfiler) and a (somewhat dated) [demo](https://share.streamlit.io/pnnl/deepdataprofiler/frontend/main_streamlit.py).

